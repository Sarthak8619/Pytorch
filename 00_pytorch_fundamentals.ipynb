{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d82077c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d03db1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bcaaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e148235a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e456e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bd74d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afef316d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a042a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[5,2],\n",
    "                       [3,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2556ca83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfc919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2dfc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[[3,9,6],\n",
    "                       [4,8,6],\n",
    "                       [23,2,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7394a95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377d208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0e185ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7010, 0.3682, 0.4297, 0.9123, 0.1974],\n",
       "         [0.7236, 0.3998, 0.5250, 0.6047, 0.4045],\n",
       "         [0.2915, 0.3479, 0.6308, 0.8877, 0.0727],\n",
       "         [0.7467, 0.3594, 0.4448, 0.3552, 0.5256]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(4,5))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3ef400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3858, 0.9046, 0.6596, 0.8866],\n",
       "          [0.8737, 0.8935, 0.5844, 0.7180],\n",
       "          [0.6121, 0.0878, 0.1719, 0.5075],\n",
       "          [0.5291, 0.6514, 0.8339, 0.8653],\n",
       "          [0.7187, 0.5766, 0.9433, 0.0077]],\n",
       " \n",
       "         [[0.1364, 0.1412, 0.7565, 0.0051],\n",
       "          [0.7613, 0.5716, 0.2764, 0.8604],\n",
       "          [0.3280, 0.8149, 0.3422, 0.1196],\n",
       "          [0.6150, 0.6506, 0.3804, 0.7927],\n",
       "          [0.8874, 0.6342, 0.6390, 0.6960]],\n",
       " \n",
       "         [[0.5176, 0.9761, 0.3221, 0.7084],\n",
       "          [0.3677, 0.9168, 0.6114, 0.1193],\n",
       "          [0.1848, 0.4466, 0.3684, 0.0241],\n",
       "          [0.8836, 0.3900, 0.0644, 0.6318],\n",
       "          [0.5943, 0.5409, 0.6430, 0.2746]]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(3,5,4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d4bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([244, 244, 3]), 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = torch.rand(size=(244,244,3))\n",
    "image_tensor.shape, image_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c1db353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]),\n",
       " torch.Size([2, 3, 4]),\n",
       " 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(2,3,4))\n",
    "zeros, zeros.shape, zeros.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d546dd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88ed6867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(start=0,end=10,step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dc567bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerostwo = torch.zeros_like(zero_to_ten)\n",
    "zerostwo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacba73c",
   "metadata": {},
   "source": [
    "## Tensor DataTypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eb3218e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.2,0.5,5,2],\n",
    "                               dtype = None, #None by default it assumes float32\n",
    "                               device = None,\n",
    "                               requires_grad = False # if True, operations performed on the tensor are recorded\n",
    "                              )\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10e776c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_64_tensor = torch.tensor([3.2,0.5,5,2],\n",
    "                               dtype = torch.float64, #None by default it assumes float32\n",
    "                               device = None,\n",
    "                               requires_grad = False # if True, operations performed on the tensor are recorded\n",
    "                              )\n",
    "float_64_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d129d",
   "metadata": {},
   "source": [
    "## Getting information from tensors \n",
    "\"what shape are my tensors? what datatype are they and where are they stored? what shape, what datatype, where where where\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b699d791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), 3, device(type='cpu'), torch.float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4,5)\n",
    "some_tensor.shape, some_tensor.ndim, some_tensor.device, some_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2fb26",
   "metadata": {},
   "source": [
    "## Manipulating Tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b0f4d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 30, 40])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,3,4])\n",
    "tensor + 10 \n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23665c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor # performing operations on tensors does not change the initial tensor unless a new value is assgned to it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24170986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_new = tensor - 1 \n",
    "tensor_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09797c",
   "metadata": {},
   "source": [
    "### Matrix multiplication is all you need \n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "The inner dimensions must match:\n",
    "-(3, 2) @ (3, 2) won't work\n",
    "-(2, 3) @ (3, 2) will work\n",
    "-(3, 2) @ (2, 3) will work\n",
    "The resulting matrix has the shape of the outer dimensions:\n",
    "-(2, 3) @ (3, 2) -> (2, 2)\n",
    "-|(3, 2) @ (2, 3) -> (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3000c27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  9, 16])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edafa3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor,tensor) # EXAMPLE OF torch.matmul([1*1 + 2*2 + 3*3] = [14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f3c62",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning (shape errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a59adcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m tensor1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                         [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                         [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      5\u001b[0m                         [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      6\u001b[0m                         [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This gives an error because the shapes cannot be multiplied\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# tensor 1 shape = 3 @ 2\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# tensor 2 shape = 3 @ 2 \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# correct tensor2 will be of dimension 2 @ 3 \u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]],dtype=torch.float32)\n",
    "tensor2 = torch.tensor([[7,10],\n",
    "                        [8,11],\n",
    "                        [9,12]],dtype=torch.float32)\n",
    "torch.matmul(tensor1,tensor2) \n",
    "# This gives an error because the shapes cannot be multiplied\n",
    "# tensor 1 shape = 3 @ 2\n",
    "# tensor 2 shape = 3 @ 2 \n",
    "# correct tensor2 will be of dimension 2 @ 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b717054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor1,tensor2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bebe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor1\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a591ac4",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a9915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc30d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum = 0\n",
      "Maximum = 90\n",
      "Average = 45.0\n",
      "Total = 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum = {x.min()}\")\n",
    "print(f\"Maximum = {x.max()}\")\n",
    "#print(f\"Average = {x.mean()}\") this will throw an error \n",
    "print(f\"Average = {x.type(torch.float32).mean()}\")\n",
    "print(f\"Total = {x.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da421e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index where maximum value occurs is 15\n",
      "Index where minimum value occurs is 0\n"
     ]
    }
   ],
   "source": [
    "y = torch.arange(20,100,5)\n",
    "y\n",
    "\n",
    "print(f\"Index where maximum value occurs is {y.argmax()}\")\n",
    "print(f\"Index where minimum value occurs is {y.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2dae8b",
   "metadata": {},
   "source": [
    "## Change tensor datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c624f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0,50,10)\n",
    "print(t1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382fee2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float32 = tensor.type(torch.float32)\n",
    "tensor_float32.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464541cc",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ce0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd159c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b7ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae82049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b2b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
